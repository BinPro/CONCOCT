#!/usr/bin/env python
from __future__ import division

import sys
import logging
import multiprocessing

import pandas as p

from itertools import chain

from sklearn.mixture import GMM

from concoct.output import Output
from concoct.parser import arguments
from concoct.cluster import cluster
from concoct.input import load_composition, load_coverage
from concoct.transform import perform_pca, perform_split_pca

def main(comp_file, cov_file, kmer_len, threshold, 
         read_length, clusters_range, cov_range, 
         split_pca, inits, iters, outdir, pipe,
         max_n_processors, pca_components, random_seed,
         cv_type, args=None):

    # Main node is if we're
    # 1. using MPI and are rank 0 
    # or 
    # 2. if we are not using MPI
    main_node = ((max_n_processors.use_mpi and 
                  max_n_processors.rank==0) or 
                 not max_n_processors.use_mpi)

    if main_node:
        # Initialize output handling
        Output(outdir,args)

        composition, contig_lengths, threshold_filter = \
            load_composition(comp_file, kmer_len, threshold)
        cov, cov_range = load_coverage(cov_file, cov_range, contig_lengths)

        joined = composition.join(
            cov.ix[:,cov_range[0]:cov_range[1]],how="inner")

        if split_pca:
            cov_d = cov[threshold_filter].ix[:,cov_range[0]:cov_range[1]]
                
            # Fix special case in pca_components
            if pca_components[0] == "All":
                pca_components = (cov_d.shape[1],pca_components[1])
            if pca_components[1] == "All":
                pca_components = (pca_components[0],
                                  composition[threshold_filter].shape[1])

            transform_filter, cov_pca, comp_pca = \
                perform_split_pca(cov_d, composition[threshold_filter], pca_components)
        else:
            # Fix special cas in pca_components
            if pca_components == "All":
                pca_components = joined[threshold_filter].shape[1]
            #PCA on the contigs that have kmer count greater than threshold
            transform_filter, pca = perform_pca(joined[threshold_filter], pca_components)

        Output.write_original_data(joined[threshold_filter],threshold)
        Output.write_pca(transform_filter,
                         threshold,cov[threshold_filter].index)
        logging.info('PCA transformed data.')
        cluster_args = []
        for c in clusters_range:
            cluster_args.append((c,cv_type,inits,iters,transform_filter,random_seed))

    #This code should be executed by all threads
    if max_n_processors.use_mpi:
        if not main_node:
            cluster_args = []
        cluster_args = max_n_processors.comm.bcast(cluster_args, root=0)
        result = map(cluster,cluster_args[max_n_processors.rank::max_n_processors.size])
        #Gather all results to root process again
        results = max_n_processors.comm.gather(result, root=0)
        if main_node:
            results = list(chain(*results))
    
    else:
        pool = multiprocessing.Pool(processes=max_n_processors.size)
        results = pool.map(cluster,cluster_args)

    if main_node:
        bics = [(r[0],r[1]) for r in results]
        Output.write_bic(bics)
        min_bic, optimal_c, converged = min(results,key=lambda x: x[0])
        if not converged:
            logging.error(("Optimal bic score was reached for non convergent "
                           "cluster number {0}, exiting without clustering "
                           "output").format(optimal_c))
            sys.exit(-1)
        gmm = GMM(n_components=optimal_c, covariance_type=cv_type, n_init=inits,
                  n_iter=iters,random_state=random_seed).fit(transform_filter)
    
        if split_pca:
            # Transform both unfiltered datasets separately before joining
            joined_transform, _, _ = perform_split_pca(cov, composition, 
                                                       pca_components,
                                                       use_pcas = (cov_pca,comp_pca))

            joined["clustering"] = gmm.predict(joined_transform)
                        
        else:
            joined["clustering"] = gmm.predict(pca.transform(joined))
            Output.write_cluster_means(pca.inverse_transform(gmm.means_),
                                       threshold,c)
        # Covariance matrix is three dimensional if full
        if cv_type == 'full':
            for i,v in enumerate(gmm.covars_):
                if not split_pca:
                    Output.write_cluster_variance(pca.inverse_transform(v),
                                                  threshold,i)
                Output.write_cluster_pca_variances(v,threshold,i)
        else:
            if not split_pca:
                Output.write_cluster_variance(pca.inverse_transform(gmm.covars_),
                                              threshold,0)
            Output.write_cluster_pca_variances(gmm.covars_,threshold,0)
            
        Output.write_clustering(joined,threshold_filter,threshold,c,pipe)
        Output.write_cluster_pca_means(gmm.means_,threshold,c)
            
        pp = gmm.predict_proba(transform_filter)
    
        Output.write_cluster_responsibilities(
            pp,
            threshold,c)
        logging.info("CONCOCT Finished")


        
if __name__=="__main__":
    args = arguments()
    if args.split_pca:
        if args.coverage_percentage_pca == 100:
            cov = "All"
        else:
            cov = args.coverage_percentage_pca/100.0
        if args.composition_percentage_pca == 100:
            comp = "All"
        else:
            comp = args.composition_percentage_pca/100.0
        pca_components = (cov,comp)
                          
    else:
        if args.total_percentage_pca == 100:
            pca_components = "All"
        else:
            pca_components = args.total_percentage_pca/100.0

    results = main(args.composition_file, 
                   args.coverage_file,
                   args.kmer_length, 
                   args.limit_kmer_count, 
                   args.read_length, 
                   args.clusters, 
                   args.coverage_file_column_names, 
                   args.split_pca, 
                   args.executions, 
                   args.iterations, 
                   args.basename, 
                   args.pipe,
                   args.max_n_processors,
                   pca_components,
                   args.force_seed,
                   args.covariance_type,
                   args)
    if (args.max_n_processors.use_mpi and args.max_n_processors.rank==0) or not args.max_n_processors.use_mpi:
        print >> sys.stderr, "CONCOCT Finished, the log shows how it went."
